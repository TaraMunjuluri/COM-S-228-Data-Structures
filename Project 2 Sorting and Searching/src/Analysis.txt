Starting off with insertion sort we notice that it takes the longest amount of time. Its complexity is O(n2) while efficient enough for smaller values we can see that its number of comparisons and time is larger than the rest. This sort runs efficiently when small and drops as more sorts are needed. The repeated insertion of values racks up huge amounts of comparison when compared to the others. Very simple sort that works when n = 10 but is slow when n = 1000000 requiring less memory. This matches Big O but is cut even shorter on my project due to the performance of my machine.
When looking at merge sort we can see it is much more efficient requiring fewer comparisons and time as insertion. Its complexity is O(nlogn) yielding higher memory due to the addition of a second array. Due to the recursion, this sorts well when n is a large value. This could be due to the fact that the sequential access of this sort scales very well with the list and arrays. When n = 1000000 merge is speedy fast sorting 250 thousand in a single second.
Lastly, QuickSort wipes the floor when it comes to time to sort. With its complexity also being O(nlogn) makes this require way less amount of time as insertion and merge. While being similar in the number of comparisons. When the pivot is the leftmost element its efficiency does drop. Due to the efficiency of the recursions inner loop, we can see why it beats out merge sort slightly but kills its momentum due to pivot. I did notice that pivot played a huge toll in its efficiency.
